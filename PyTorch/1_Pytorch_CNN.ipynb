{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMp4qm0O8+M3kzdrV6fES8M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehrshad-sdtn/DeepLearning/blob/master/PyTorch/1_Pytorch_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoMtnrm3yMcp"
      },
      "outputs": [],
      "source": [
        "# prompt: import all the necessary packages for common pytorch programs\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels= in_channels, out_channels= 8, kernel_size= (3, 3), stride= (1, 1), padding= (1, 1))\n",
        "        self.pool = nn.MaxPool2d(kernel_size= (2, 2), stride= (2, 2))\n",
        "        self.conv2 = nn.Conv2d(in_channels= 8, out_channels= 16, kernel_size= (3, 3), stride= (1, 1), padding= (1, 1))\n",
        "        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "JcVDDGATSZDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf2q8xlmIi05",
        "outputId": "5d7048c2-c0ba-4972-9d2c-15fd4b57696a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "learning_rate = 0.0001\n",
        "batch_size = 64\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "P6jwGiRrIlh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load Data\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "DOvAExljIu45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize network\n",
        "model = CNN(in_channels=1, num_classes= num_classes).to(device)"
      ],
      "metadata": {
        "id": "GkccL0K0JH9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "6K13fg05J1Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check accurcy on training and test\n",
        "def check_accuracy(loader, model):\n",
        "  if loader.dataset.train:\n",
        "    print('Checking accuracy on training data:')\n",
        "  else:\n",
        "    print('Checking accuracy on test data')\n",
        "\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x = x.to(device= device)\n",
        "      y = y.to(device= device)\n",
        "\n",
        "      scores = model(x) # 64, 10\n",
        "      _, predictions = scores.max(1)\n",
        "      num_correct += (predictions == y).sum()\n",
        "      num_samples += predictions.size(0)\n",
        "\n",
        "    print(f\" {float(num_correct)/float(num_samples)*100:.2f}%\")\n",
        "    model.train()\n",
        "\n",
        "\n",
        "# train\n",
        "for epoch in range(num_epochs):\n",
        "  for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "    # data shaping\n",
        "    data = data.to(device)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    # forward\n",
        "    scores = model(data)\n",
        "    loss = criterion(scores, targets)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # gradient descent\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f\"Epoch {epoch+1}/{num_epochs}: loss {loss}\")\n",
        "  check_accuracy(train_loader, model)\n",
        "  check_accuracy(test_loader, model)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLWSGvzsJ9Pt",
        "outputId": "6aaac674-4a19-4bfc-f1ce-bc21c0f2072e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10: loss 0.5718998908996582\n",
            "Checking accuracy on training data:\n",
            " 87.96%\n",
            "Checking accuracy on test data\n",
            " 88.93%\n",
            "Epoch 2/10: loss 0.45791107416152954\n",
            "Checking accuracy on training data:\n",
            " 91.42%\n",
            "Checking accuracy on test data\n",
            " 92.07%\n",
            "Epoch 3/10: loss 0.17000322043895721\n",
            "Checking accuracy on training data:\n",
            " 93.38%\n",
            "Checking accuracy on test data\n",
            " 93.85%\n",
            "Epoch 4/10: loss 0.08540171384811401\n",
            "Checking accuracy on training data:\n",
            " 94.36%\n",
            "Checking accuracy on test data\n",
            " 94.82%\n",
            "Epoch 5/10: loss 0.1383964568376541\n",
            "Checking accuracy on training data:\n",
            " 95.18%\n",
            "Checking accuracy on test data\n",
            " 95.46%\n",
            "Epoch 6/10: loss 0.1378350853919983\n",
            "Checking accuracy on training data:\n",
            " 95.81%\n",
            "Checking accuracy on test data\n",
            " 96.05%\n",
            "Epoch 7/10: loss 0.06640152633190155\n",
            "Checking accuracy on training data:\n",
            " 96.27%\n",
            "Checking accuracy on test data\n",
            " 96.53%\n",
            "Epoch 8/10: loss 0.05078206583857536\n",
            "Checking accuracy on training data:\n",
            " 96.63%\n",
            "Checking accuracy on test data\n",
            " 96.85%\n",
            "Epoch 9/10: loss 0.054490819573402405\n",
            "Checking accuracy on training data:\n",
            " 96.94%\n",
            "Checking accuracy on test data\n",
            " 97.11%\n",
            "Epoch 10/10: loss 0.007031313143670559\n",
            "Checking accuracy on training data:\n",
            " 97.17%\n",
            "Checking accuracy on test data\n",
            " 97.24%\n"
          ]
        }
      ]
    }
  ]
}