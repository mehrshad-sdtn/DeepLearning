{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOw6SZ45yefVGQpJU0AJD1o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehrshad-sdtn/DeepLearning/blob/master/PyTorch/2_Pytorch_RNN_LSTM_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoMtnrm3yMcp"
      },
      "outputs": [],
      "source": [
        "# prompt: import all the necessary packages for common pytorch programs\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Fully-Connected network\n",
        "hidden_size = 256\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = out.reshape(out.shape[0], -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size * sequence_length, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "        out, _ = self.rnn(x, (h0, c0))\n",
        "        out = out.reshape(out.shape[0], -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uBoWEBpYDIuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf2q8xlmIi05",
        "outputId": "5735101f-b0c4-48a1-89be-8ae2814c6b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "input_size = 28\n",
        "sequence_length = 28\n",
        "num_layers = 2\n",
        "num_classes = 10\n",
        "learning_rate = 0.0001\n",
        "batch_size = 64\n",
        "num_epochs = 5"
      ],
      "metadata": {
        "id": "P6jwGiRrIlh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load Data\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "DOvAExljIu45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize network\n",
        "model = LSTM(input_size= input_size, hidden_size= hidden_size, num_layers= num_layers, num_classes= num_classes).to(device)"
      ],
      "metadata": {
        "id": "GkccL0K0JH9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "6K13fg05J1Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
        "  print(\"=> Saving checkpoint\")\n",
        "  torch.save(state, filename)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint, model):\n",
        "  print(\"=> Loading checkpoint\")\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['state_dict'])\n",
        "\n"
      ],
      "metadata": {
        "id": "TZX-9Eb5OKt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check accurcy on training and test\n",
        "def check_accuracy(loader, model):\n",
        "  if loader.dataset.train:\n",
        "    print('Checking accuracy on training data:')\n",
        "  else:\n",
        "    print('Checking accuracy on test data')\n",
        "\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x = x.to(device= device).squeeze(1)\n",
        "      y = y.to(device= device)\n",
        "\n",
        "      scores = model(x) # 64, 10\n",
        "      _, predictions = scores.max(1)\n",
        "      num_correct += (predictions == y).sum()\n",
        "      num_samples += predictions.size(0)\n",
        "\n",
        "    print(f\" {float(num_correct)/float(num_samples)*100:.2f}%\")\n",
        "    model.train()\n",
        "\n",
        "\n",
        "\n",
        "# train\n",
        "for epoch in range(num_epochs):\n",
        "  losses = []\n",
        "  if epoch % 3 == 0:\n",
        "    checkpoint = {'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
        "    save_checkpoint(checkpoint)\n",
        "  for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "    # data shaping\n",
        "    data = data.to(device).squeeze(1)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    # forward\n",
        "    scores = model(data)\n",
        "    loss = criterion(scores, targets)\n",
        "    losses.append(loss)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # gradient descent\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f\"Epoch {epoch+1}/{num_epochs}: loss {loss}\")\n",
        "  check_accuracy(train_loader, model)\n",
        "  check_accuracy(test_loader, model)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLWSGvzsJ9Pt",
        "outputId": "0aa91b31-9e12-47b8-abbb-54bc6e10d439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5: loss 0.09761921316385269\n",
            "Checking accuracy on training data:\n",
            " 93.16%\n",
            "Checking accuracy on test data\n",
            " 93.50%\n",
            "Epoch 2/5: loss 0.0966176837682724\n",
            "Checking accuracy on training data:\n",
            " 95.85%\n",
            "Checking accuracy on test data\n",
            " 95.80%\n",
            "Epoch 3/5: loss 0.2856576442718506\n",
            "Checking accuracy on training data:\n",
            " 96.95%\n",
            "Checking accuracy on test data\n",
            " 96.79%\n",
            "Epoch 4/5: loss 0.10122382640838623\n",
            "Checking accuracy on training data:\n",
            " 97.77%\n",
            "Checking accuracy on test data\n",
            " 97.35%\n",
            "Epoch 5/5: loss 0.14088431000709534\n",
            "Checking accuracy on training data:\n",
            " 98.10%\n",
            "Checking accuracy on test data\n",
            " 97.70%\n"
          ]
        }
      ]
    }
  ]
}